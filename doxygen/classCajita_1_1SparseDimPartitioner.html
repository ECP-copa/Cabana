<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Cabana: Cajita::SparseDimPartitioner&lt; Device, CellPerTileDim, NumSpaceDim &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Cabana
   &#160;<span id="projectnumber">1.0-dev</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceCajita.html">Cajita</a></li><li class="navelem"><a class="el" href="classCajita_1_1SparseDimPartitioner.html">SparseDimPartitioner</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="classCajita_1_1SparseDimPartitioner-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Cajita::SparseDimPartitioner&lt; Device, CellPerTileDim, NumSpaceDim &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="Cajita__SparseDimPartitioner_8hpp_source.html">Cajita_SparseDimPartitioner.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for Cajita::SparseDimPartitioner&lt; Device, CellPerTileDim, NumSpaceDim &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classCajita_1_1SparseDimPartitioner__inherit__graph.png" border="0" usemap="#aCajita_1_1SparseDimPartitioner_3_01Device_00_01CellPerTileDim_00_01NumSpaceDim_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="aCajita_1_1SparseDimPartitioner_3_01Device_00_01CellPerTileDim_00_01NumSpaceDim_01_4_inherit__map" id="aCajita_1_1SparseDimPartitioner_3_01Device_00_01CellPerTileDim_00_01NumSpaceDim_01_4_inherit__map">
<area shape="rect" title=" " alt="" coords="5,80,203,136"/>
<area shape="rect" href="classCajita_1_1BlockPartitioner.html" title=" " alt="" coords="7,5,201,32"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for Cajita::SparseDimPartitioner&lt; Device, CellPerTileDim, NumSpaceDim &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classCajita_1_1SparseDimPartitioner__coll__graph.png" border="0" usemap="#aCajita_1_1SparseDimPartitioner_3_01Device_00_01CellPerTileDim_00_01NumSpaceDim_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="aCajita_1_1SparseDimPartitioner_3_01Device_00_01CellPerTileDim_00_01NumSpaceDim_01_4_coll__map" id="aCajita_1_1SparseDimPartitioner_3_01Device_00_01CellPerTileDim_00_01NumSpaceDim_01_4_coll__map">
<area shape="rect" title=" " alt="" coords="5,80,203,136"/>
<area shape="rect" href="classCajita_1_1BlockPartitioner.html" title=" " alt="" coords="7,5,201,32"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCajita_1_1SparseDimPartitioner_1_1SubWorkloadFunctor.html">SubWorkloadFunctor</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">functor to compute the sub workload in a given region (from the prefix sum)  <a href="structCajita_1_1SparseDimPartitioner_1_1SubWorkloadFunctor.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a126c831e61b841a22c0d6ded672fab9c"><td class="memItemLeft" align="right" valign="top"><a id="a126c831e61b841a22c0d6ded672fab9c"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a126c831e61b841a22c0d6ded672fab9c">device_type</a> = Device</td></tr>
<tr class="memdesc:a126c831e61b841a22c0d6ded672fab9c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kokkos device type. <br /></td></tr>
<tr class="separator:a126c831e61b841a22c0d6ded672fab9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f4a1817237e635f3441a9b51865702b"><td class="memItemLeft" align="right" valign="top"><a id="a9f4a1817237e635f3441a9b51865702b"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a9f4a1817237e635f3441a9b51865702b">memory_space</a> = typename Device::memory_space</td></tr>
<tr class="memdesc:a9f4a1817237e635f3441a9b51865702b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kokkos memory space. <br /></td></tr>
<tr class="separator:a9f4a1817237e635f3441a9b51865702b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdb1ad0ac9ba5073f2f44fb11e24b3fb"><td class="memItemLeft" align="right" valign="top"><a id="afdb1ad0ac9ba5073f2f44fb11e24b3fb"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#afdb1ad0ac9ba5073f2f44fb11e24b3fb">execution_space</a> = typename Device::execution_space</td></tr>
<tr class="memdesc:afdb1ad0ac9ba5073f2f44fb11e24b3fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kokkos execution space. <br /></td></tr>
<tr class="separator:afdb1ad0ac9ba5073f2f44fb11e24b3fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73effa5eb6293e8ea07ec1fd289f8650"><td class="memItemLeft" align="right" valign="top"><a id="a73effa5eb6293e8ea07ec1fd289f8650"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a73effa5eb6293e8ea07ec1fd289f8650">workload_view</a> = Kokkos::View&lt; int ***, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a9f4a1817237e635f3441a9b51865702b">memory_space</a> &gt;</td></tr>
<tr class="memdesc:a73effa5eb6293e8ea07ec1fd289f8650"><td class="mdescLeft">&#160;</td><td class="mdescRight">Workload device view. <br /></td></tr>
<tr class="separator:a73effa5eb6293e8ea07ec1fd289f8650"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af858a4966548f5e242b3fd9218e78075"><td class="memItemLeft" align="right" valign="top"><a id="af858a4966548f5e242b3fd9218e78075"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#af858a4966548f5e242b3fd9218e78075">partition_view</a> = Kokkos::View&lt; int *[<a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a>], <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a9f4a1817237e635f3441a9b51865702b">memory_space</a> &gt;</td></tr>
<tr class="memdesc:af858a4966548f5e242b3fd9218e78075"><td class="mdescLeft">&#160;</td><td class="mdescRight">Partition device view. <br /></td></tr>
<tr class="separator:af858a4966548f5e242b3fd9218e78075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e63e1346084f65db1fa663474808b21"><td class="memItemLeft" align="right" valign="top"><a id="a8e63e1346084f65db1fa663474808b21"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a8e63e1346084f65db1fa663474808b21">workload_view_host</a> = Kokkos::View&lt; int ***, typename execution_space::array_layout, Kokkos::HostSpace &gt;</td></tr>
<tr class="memdesc:a8e63e1346084f65db1fa663474808b21"><td class="mdescLeft">&#160;</td><td class="mdescRight">Workload host view. <br /></td></tr>
<tr class="separator:a8e63e1346084f65db1fa663474808b21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a863b419f77e321c369a80a61ff80387d"><td class="memItemLeft" align="right" valign="top"><a id="a863b419f77e321c369a80a61ff80387d"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a863b419f77e321c369a80a61ff80387d">partition_view_host</a> = Kokkos::View&lt; int *[<a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a>], typename execution_space::array_layout, Kokkos::HostSpace &gt;</td></tr>
<tr class="memdesc:a863b419f77e321c369a80a61ff80387d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Partition host view. <br /></td></tr>
<tr class="separator:a863b419f77e321c369a80a61ff80387d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ad7ad6c77a89dcdb20c164daddd6f7e44"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#ad7ad6c77a89dcdb20c164daddd6f7e44">SparseDimPartitioner</a> (MPI_Comm comm, float max_workload_coeff, int workload_num, int num_step_rebalance, const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;global_cells_per_dim, int max_optimize_iteration=10)</td></tr>
<tr class="memdesc:ad7ad6c77a89dcdb20c164daddd6f7e44"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor - automatically compute ranks_per_dim from MPI communicator.  <a href="classCajita_1_1SparseDimPartitioner.html#ad7ad6c77a89dcdb20c164daddd6f7e44">More...</a><br /></td></tr>
<tr class="separator:ad7ad6c77a89dcdb20c164daddd6f7e44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1802f0699c5729a38c9512713057efcb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a1802f0699c5729a38c9512713057efcb">SparseDimPartitioner</a> (MPI_Comm comm, float max_workload_coeff, int workload_num, int num_step_rebalance, const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;ranks_per_dim, const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;global_cells_per_dim, int max_optimize_iteration=10)</td></tr>
<tr class="memdesc:a1802f0699c5729a38c9512713057efcb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor - user-defined ranks_per_dim communicator.  <a href="classCajita_1_1SparseDimPartitioner.html#a1802f0699c5729a38c9512713057efcb">More...</a><br /></td></tr>
<tr class="separator:a1802f0699c5729a38c9512713057efcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a7a673396816fd06d2b026f26c036c9"><td class="memItemLeft" align="right" valign="top">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a2a7a673396816fd06d2b026f26c036c9">ranksPerDimension</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:a2a7a673396816fd06d2b026f26c036c9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the number of MPI ranks in each dimension of the grid from the given MPI communicator.  <a href="classCajita_1_1SparseDimPartitioner.html#a2a7a673396816fd06d2b026f26c036c9">More...</a><br /></td></tr>
<tr class="separator:a2a7a673396816fd06d2b026f26c036c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af68f61d079af0ca032d44a1d43e2069a"><td class="memItemLeft" align="right" valign="top">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#af68f61d079af0ca032d44a1d43e2069a">ranksPerDimension</a> (MPI_Comm comm, const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;) const override</td></tr>
<tr class="memdesc:af68f61d079af0ca032d44a1d43e2069a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of MPI ranks in each dimension of the grid from the given MPI communicator.  <a href="classCajita_1_1SparseDimPartitioner.html#af68f61d079af0ca032d44a1d43e2069a">More...</a><br /></td></tr>
<tr class="separator:af68f61d079af0ca032d44a1d43e2069a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e3c5f54f8fe08ec2ec88aefb8415bb7"><td class="memItemLeft" align="right" valign="top">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a1e3c5f54f8fe08ec2ec88aefb8415bb7">ownedTilesPerDimension</a> (MPI_Comm cart_comm) const</td></tr>
<tr class="memdesc:a1e3c5f54f8fe08ec2ec88aefb8415bb7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the tile number in each dimension owned by the current MPI rank.  <a href="classCajita_1_1SparseDimPartitioner.html#a1e3c5f54f8fe08ec2ec88aefb8415bb7">More...</a><br /></td></tr>
<tr class="separator:a1e3c5f54f8fe08ec2ec88aefb8415bb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2de4b75cfd8ae87ce76c223d0a6aa2a2"><td class="memItemLeft" align="right" valign="top">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a2de4b75cfd8ae87ce76c223d0a6aa2a2">ownedCellsPerDimension</a> (MPI_Comm cart_comm) const</td></tr>
<tr class="memdesc:a2de4b75cfd8ae87ce76c223d0a6aa2a2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the cell number in each dimension owned by the current MPI rank.  <a href="classCajita_1_1SparseDimPartitioner.html#a2de4b75cfd8ae87ce76c223d0a6aa2a2">More...</a><br /></td></tr>
<tr class="separator:a2de4b75cfd8ae87ce76c223d0a6aa2a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16438a4249d049575d7b2a76f1965490"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a16438a4249d049575d7b2a76f1965490">ownedTileInfo</a> (MPI_Comm cart_comm, std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;owned_num_tile, std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;global_tile_offset) const</td></tr>
<tr class="memdesc:a16438a4249d049575d7b2a76f1965490"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the owned number of tiles and the global tile offset of the current MPI rank.  <a href="classCajita_1_1SparseDimPartitioner.html#a16438a4249d049575d7b2a76f1965490">More...</a><br /></td></tr>
<tr class="separator:a16438a4249d049575d7b2a76f1965490"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f1ccee3a257e7c0164bd31a62391473"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a0f1ccee3a257e7c0164bd31a62391473">ownedCellInfo</a> (MPI_Comm cart_comm, const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;, std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;owned_num_cell, std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;global_cell_offset) const override</td></tr>
<tr class="memdesc:a0f1ccee3a257e7c0164bd31a62391473"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the owned number of cells and the global cell offset of the current MPI rank.  <a href="classCajita_1_1SparseDimPartitioner.html#a0f1ccee3a257e7c0164bd31a62391473">More...</a><br /></td></tr>
<tr class="separator:a0f1ccee3a257e7c0164bd31a62391473"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88712aa69d9faaaeba720aadb3bc389d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a88712aa69d9faaaeba720aadb3bc389d">initializeRecPartition</a> (std::vector&lt; int &gt; &amp;rec_partition_i, std::vector&lt; int &gt; &amp;rec_partition_j, std::vector&lt; int &gt; &amp;rec_partition_k)</td></tr>
<tr class="memdesc:a88712aa69d9faaaeba720aadb3bc389d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize the tile partition; partition in each dimension has the form [0, p_1, ..., p_n, total_tile_num], so the partition would be [0, p_1), [p_1, p_2) ... [p_n, total_tile_num].  <a href="classCajita_1_1SparseDimPartitioner.html#a88712aa69d9faaaeba720aadb3bc389d">More...</a><br /></td></tr>
<tr class="separator:a88712aa69d9faaaeba720aadb3bc389d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a465c6a300918ced96115b61d2d4396db"><td class="memItemLeft" align="right" valign="top"><a id="a465c6a300918ced96115b61d2d4396db"></a>
std::array&lt; std::vector&lt; int &gt;, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a465c6a300918ced96115b61d2d4396db">getCurrentPartition</a> ()</td></tr>
<tr class="memdesc:a465c6a300918ced96115b61d2d4396db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the current partition. Copy partition from the device view to host std::array&lt;vector&gt; <br /></td></tr>
<tr class="separator:a465c6a300918ced96115b61d2d4396db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac32db297309910f0b274576ee6991e13"><td class="memItemLeft" align="right" valign="top"><a id="ac32db297309910f0b274576ee6991e13"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#ac32db297309910f0b274576ee6991e13">resetWorkload</a> ()</td></tr>
<tr class="memdesc:ac32db297309910f0b274576ee6991e13"><td class="mdescLeft">&#160;</td><td class="mdescRight">set all elements in _workload_per_tile and _workload_prefix_sum matrix to 0 <br /></td></tr>
<tr class="separator:ac32db297309910f0b274576ee6991e13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b8e66f13525d6a3e0eb64641d986bb1"><td class="memTemplParams" colspan="2">template&lt;class ParticlePosViewType , typename ArrayType , typename CellUnit &gt; </td></tr>
<tr class="memitem:a9b8e66f13525d6a3e0eb64641d986bb1"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a9b8e66f13525d6a3e0eb64641d986bb1">computeLocalWorkLoad</a> (const ParticlePosViewType &amp;view, int particle_num, const ArrayType &amp;global_lower_corner, const CellUnit dx)</td></tr>
<tr class="memdesc:a9b8e66f13525d6a3e0eb64641d986bb1"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the workload in the current MPI rank from particle positions (each particle count for 1 workload value)  <a href="classCajita_1_1SparseDimPartitioner.html#a9b8e66f13525d6a3e0eb64641d986bb1">More...</a><br /></td></tr>
<tr class="separator:a9b8e66f13525d6a3e0eb64641d986bb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae937f8e12803499998c572c87e76740f"><td class="memTemplParams" colspan="2">template&lt;class SparseMapType &gt; </td></tr>
<tr class="memitem:ae937f8e12803499998c572c87e76740f"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#ae937f8e12803499998c572c87e76740f">computeLocalWorkLoad</a> (const SparseMapType &amp;sparseMap)</td></tr>
<tr class="memdesc:ae937f8e12803499998c572c87e76740f"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the workload in the current MPI rank from sparseMap (the workload of a tile is 1 if the tile is occupied, 0 otherwise)  <a href="classCajita_1_1SparseDimPartitioner.html#ae937f8e12803499998c572c87e76740f">More...</a><br /></td></tr>
<tr class="separator:ae937f8e12803499998c572c87e76740f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9226600c877af1b34011278677e6d271"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a9226600c877af1b34011278677e6d271">computeFullPrefixSum</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:a9226600c877af1b34011278677e6d271"><td class="mdescLeft">&#160;</td><td class="mdescRight"><ol type="1">
<li>reduce the total workload in all MPI ranks; 2. compute the workload prefix sum matrix for all MPI ranks </li>
</ol>
 <a href="classCajita_1_1SparseDimPartitioner.html#a9226600c877af1b34011278677e6d271">More...</a><br /></td></tr>
<tr class="separator:a9226600c877af1b34011278677e6d271"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1de5559f31df44046dd4fd231a9d7fd2"><td class="memTemplParams" colspan="2">template&lt;class ParticlePosViewType , typename ArrayType , typename CellUnit &gt; </td></tr>
<tr class="memitem:a1de5559f31df44046dd4fd231a9d7fd2"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a1de5559f31df44046dd4fd231a9d7fd2">optimizePartition</a> (const ParticlePosViewType &amp;view, int particle_num, const ArrayType &amp;global_lower_corner, const CellUnit dx, MPI_Comm comm)</td></tr>
<tr class="memdesc:a1de5559f31df44046dd4fd231a9d7fd2"><td class="mdescLeft">&#160;</td><td class="mdescRight">iteratively optimize the partition  <a href="classCajita_1_1SparseDimPartitioner.html#a1de5559f31df44046dd4fd231a9d7fd2">More...</a><br /></td></tr>
<tr class="separator:a1de5559f31df44046dd4fd231a9d7fd2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1db7d9a2fd6291775629256bb1fb1957"><td class="memTemplParams" colspan="2">template&lt;class SparseMapType &gt; </td></tr>
<tr class="memitem:a1db7d9a2fd6291775629256bb1fb1957"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a1db7d9a2fd6291775629256bb1fb1957">optimizePartition</a> (const SparseMapType &amp;sparseMap, MPI_Comm comm)</td></tr>
<tr class="memdesc:a1db7d9a2fd6291775629256bb1fb1957"><td class="mdescLeft">&#160;</td><td class="mdescRight">iteratively optimize the partition  <a href="classCajita_1_1SparseDimPartitioner.html#a1db7d9a2fd6291775629256bb1fb1957">More...</a><br /></td></tr>
<tr class="separator:a1db7d9a2fd6291775629256bb1fb1957"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0c1e99bbd57d2964aa89fb1eef465b3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#af0c1e99bbd57d2964aa89fb1eef465b3">optimizePartition</a> (bool &amp;is_changed, int iter_seed)</td></tr>
<tr class="memdesc:af0c1e99bbd57d2964aa89fb1eef465b3"><td class="mdescLeft">&#160;</td><td class="mdescRight">optimize the partition in three dimensions seperately  <a href="classCajita_1_1SparseDimPartitioner.html#af0c1e99bbd57d2964aa89fb1eef465b3">More...</a><br /></td></tr>
<tr class="separator:af0c1e99bbd57d2964aa89fb1eef465b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac45384427949c06440ad327a454d614c"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#ac45384427949c06440ad327a454d614c">currentRankWorkload</a> (MPI_Comm cart_comm)</td></tr>
<tr class="memdesc:ac45384427949c06440ad327a454d614c"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the total workload on the current MPI rank  <a href="classCajita_1_1SparseDimPartitioner.html#ac45384427949c06440ad327a454d614c">More...</a><br /></td></tr>
<tr class="separator:ac45384427949c06440ad327a454d614c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0adefd6b4bbd92bc3e8f3394ed811b20"><td class="memTemplParams" colspan="2">template&lt;typename PartitionViewHost , typename WorkloadViewHost &gt; </td></tr>
<tr class="memitem:a0adefd6b4bbd92bc3e8f3394ed811b20"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a0adefd6b4bbd92bc3e8f3394ed811b20">currentRankWorkload</a> (MPI_Comm cart_comm, PartitionViewHost &amp;rec_view, WorkloadViewHost &amp;prefix_sum_view)</td></tr>
<tr class="memdesc:a0adefd6b4bbd92bc3e8f3394ed811b20"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the total workload on the current MPI rank  <a href="classCajita_1_1SparseDimPartitioner.html#a0adefd6b4bbd92bc3e8f3394ed811b20">More...</a><br /></td></tr>
<tr class="separator:a0adefd6b4bbd92bc3e8f3394ed811b20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add6b2aef303123d5bdce3a4757c4a9bc"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#add6b2aef303123d5bdce3a4757c4a9bc">averageRankWorkload</a> ()</td></tr>
<tr class="memdesc:add6b2aef303123d5bdce3a4757c4a9bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the average workload on each MPI rank  <a href="classCajita_1_1SparseDimPartitioner.html#add6b2aef303123d5bdce3a4757c4a9bc">More...</a><br /></td></tr>
<tr class="separator:add6b2aef303123d5bdce3a4757c4a9bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51dfc55970b2c7f08225c3a163847bdd"><td class="memTemplParams" colspan="2">template&lt;typename WorkloadViewHost &gt; </td></tr>
<tr class="memitem:a51dfc55970b2c7f08225c3a163847bdd"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a51dfc55970b2c7f08225c3a163847bdd">averageRankWorkload</a> (WorkloadViewHost &amp;prefix_sum_view)</td></tr>
<tr class="memdesc:a51dfc55970b2c7f08225c3a163847bdd"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the average workload on each MPI rank  <a href="classCajita_1_1SparseDimPartitioner.html#a51dfc55970b2c7f08225c3a163847bdd">More...</a><br /></td></tr>
<tr class="separator:a51dfc55970b2c7f08225c3a163847bdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae44846c4fb2aed4672438f5561072e87"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#ae44846c4fb2aed4672438f5561072e87">computeImbalanceFactor</a> (MPI_Comm cart_comm)</td></tr>
<tr class="memdesc:ae44846c4fb2aed4672438f5561072e87"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute the imbalance factor for the current partition  <a href="classCajita_1_1SparseDimPartitioner.html#ae44846c4fb2aed4672438f5561072e87">More...</a><br /></td></tr>
<tr class="separator:ae44846c4fb2aed4672438f5561072e87"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:a652ee3297ac5b29c8b88e6042442aa6f"><td class="memItemLeft" align="right" valign="top"><a id="a652ee3297ac5b29c8b88e6042442aa6f"></a>
static constexpr std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> = NumSpaceDim</td></tr>
<tr class="memdesc:a652ee3297ac5b29c8b88e6042442aa6f"><td class="mdescLeft">&#160;</td><td class="mdescRight">dimension <br /></td></tr>
<tr class="separator:a652ee3297ac5b29c8b88e6042442aa6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abeffdd20e2001506d8c2b7257dc67a6b"><td class="memItemLeft" align="right" valign="top">static constexpr unsigned long long&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#abeffdd20e2001506d8c2b7257dc67a6b">cell_bits_per_tile_dim</a></td></tr>
<tr class="memdesc:abeffdd20e2001506d8c2b7257dc67a6b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of bits (per dimension) needed to index the cells inside a tile.  <a href="classCajita_1_1SparseDimPartitioner.html#abeffdd20e2001506d8c2b7257dc67a6b">More...</a><br /></td></tr>
<tr class="separator:abeffdd20e2001506d8c2b7257dc67a6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48f75e292caa057b5ff2bab858af6359"><td class="memItemLeft" align="right" valign="top">static constexpr unsigned long long&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1SparseDimPartitioner.html#a48f75e292caa057b5ff2bab858af6359">cell_num_per_tile_dim</a></td></tr>
<tr class="separator:a48f75e292caa057b5ff2bab858af6359"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_static_attribs_classCajita_1_1BlockPartitioner"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classCajita_1_1BlockPartitioner')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classCajita_1_1BlockPartitioner.html">Cajita::BlockPartitioner&lt; 3 &gt;</a></td></tr>
<tr class="memitem:a4c67571ff5a952b1b64c10616d43838f inherit pub_static_attribs_classCajita_1_1BlockPartitioner"><td class="memItemLeft" align="right" valign="top"><a id="a4c67571ff5a952b1b64c10616d43838f"></a>
static constexpr std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classCajita_1_1BlockPartitioner.html#a4c67571ff5a952b1b64c10616d43838f">num_space_dim</a></td></tr>
<tr class="memdesc:a4c67571ff5a952b1b64c10616d43838f inherit pub_static_attribs_classCajita_1_1BlockPartitioner"><td class="mdescLeft">&#160;</td><td class="mdescRight">Spatial dimension. <br /></td></tr>
<tr class="separator:a4c67571ff5a952b1b64c10616d43838f inherit pub_static_attribs_classCajita_1_1BlockPartitioner"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Device, unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt;<br />
class Cajita::SparseDimPartitioner&lt; Device, CellPerTileDim, NumSpaceDim &gt;</h3>

<p>Sparse mesh block partitioner. (Current Version: Support 3D only) </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Device</td><td>Kokkos device type. </td></tr>
    <tr><td class="paramname">CellPerTileDim</td><td>Cells per tile per dimension. </td></tr>
    <tr><td class="paramname">NumSpaceDim</td><td>Dimemsion (The current version support 3D only) </td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ad7ad6c77a89dcdb20c164daddd6f7e44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7ad6c77a89dcdb20c164daddd6f7e44">&#9670;&nbsp;</a></span>SparseDimPartitioner() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::<a class="el" href="classCajita_1_1SparseDimPartitioner.html">SparseDimPartitioner</a> </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>max_workload_coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>workload_num</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_step_rebalance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>global_cells_per_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max_optimize_iteration</em> = <code>10</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructor - automatically compute ranks_per_dim from MPI communicator. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">comm</td><td>MPI communicator to decide the rank nums in each dimension </td></tr>
    <tr><td class="paramname">max_workload_coeff</td><td>threshold factor for re-partition </td></tr>
    <tr><td class="paramname">workload_num</td><td>total workload(particle/tile) number, used to compute workload_threshold </td></tr>
    <tr><td class="paramname">num_step_rebalance</td><td>the simulation step number after which one should check if repartition is needed </td></tr>
    <tr><td class="paramname">global_cells_per_dim</td><td>3D array, global cells in each dimension </td></tr>
    <tr><td class="paramname">max_optimize_iteration</td><td>max iteration number to run the optimization </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1802f0699c5729a38c9512713057efcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1802f0699c5729a38c9512713057efcb">&#9670;&nbsp;</a></span>SparseDimPartitioner() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::<a class="el" href="classCajita_1_1SparseDimPartitioner.html">SparseDimPartitioner</a> </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>max_workload_coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>workload_num</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_step_rebalance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks_per_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>global_cells_per_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max_optimize_iteration</em> = <code>10</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructor - user-defined ranks_per_dim communicator. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">comm</td><td>MPI communicator to decide the rank nums in each dimension </td></tr>
    <tr><td class="paramname">max_workload_coeff</td><td>threshold factor for re-partition </td></tr>
    <tr><td class="paramname">workload_num</td><td>total workload(particle/tile) number, used to compute workload_threshold </td></tr>
    <tr><td class="paramname">num_step_rebalance</td><td>the simulation step number after which one should check if repartition is needed </td></tr>
    <tr><td class="paramname">ranks_per_dim</td><td>3D array, user-defined MPI rank constrains in per dimension </td></tr>
    <tr><td class="paramname">global_cells_per_dim</td><td>3D array, global cells in each dimension </td></tr>
    <tr><td class="paramname">max_optimize_iteration</td><td>max iteration number to run the optimization </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="add6b2aef303123d5bdce3a4757c4a9bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add6b2aef303123d5bdce3a4757c4a9bc">&#9670;&nbsp;</a></span>averageRankWorkload() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::averageRankWorkload </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the average workload on each MPI rank </p>
<dl class="section return"><dt>Returns</dt><dd>average workload on each rank </dd></dl>

</div>
</div>
<a id="a51dfc55970b2c7f08225c3a163847bdd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a51dfc55970b2c7f08225c3a163847bdd">&#9670;&nbsp;</a></span>averageRankWorkload() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<div class="memtemplate">
template&lt;typename WorkloadViewHost &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::averageRankWorkload </td>
          <td>(</td>
          <td class="paramtype">WorkloadViewHost &amp;&#160;</td>
          <td class="paramname"><em>prefix_sum_view</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the average workload on each MPI rank </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">prefix_sum_view</td><td>Host mirror of _workload_prefix_sum </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>average workload on each rank </dd></dl>

</div>
</div>
<a id="a9226600c877af1b34011278677e6d271"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9226600c877af1b34011278677e6d271">&#9670;&nbsp;</a></span>computeFullPrefixSum()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::computeFullPrefixSum </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><ol type="1">
<li>reduce the total workload in all MPI ranks; 2. compute the workload prefix sum matrix for all MPI ranks </li>
</ol>
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">comm</td><td>MPI communicator used for workload reduction </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae44846c4fb2aed4672438f5561072e87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae44846c4fb2aed4672438f5561072e87">&#9670;&nbsp;</a></span>computeImbalanceFactor()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">float <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::computeImbalanceFactor </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the imbalance factor for the current partition </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>MPI cartesian communicator </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>the imbalance factor = workload on current rank / ave_workload </dd></dl>

</div>
</div>
<a id="a9b8e66f13525d6a3e0eb64641d986bb1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b8e66f13525d6a3e0eb64641d986bb1">&#9670;&nbsp;</a></span>computeLocalWorkLoad() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<div class="memtemplate">
template&lt;class ParticlePosViewType , typename ArrayType , typename CellUnit &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::computeLocalWorkLoad </td>
          <td>(</td>
          <td class="paramtype">const ParticlePosViewType &amp;&#160;</td>
          <td class="paramname"><em>view</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>particle_num</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ArrayType &amp;&#160;</td>
          <td class="paramname"><em>global_lower_corner</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const CellUnit&#160;</td>
          <td class="paramname"><em>dx</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the workload in the current MPI rank from particle positions (each particle count for 1 workload value) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">view</td><td>particle positions view </td></tr>
    <tr><td class="paramname">particle_num</td><td>total particle number </td></tr>
    <tr><td class="paramname">global_lower_corner</td><td>the coordinate of the domain global lower corner </td></tr>
    <tr><td class="paramname">dx</td><td>cell dx size </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae937f8e12803499998c572c87e76740f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae937f8e12803499998c572c87e76740f">&#9670;&nbsp;</a></span>computeLocalWorkLoad() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<div class="memtemplate">
template&lt;class SparseMapType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::computeLocalWorkLoad </td>
          <td>(</td>
          <td class="paramtype">const SparseMapType &amp;&#160;</td>
          <td class="paramname"><em>sparseMap</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the workload in the current MPI rank from sparseMap (the workload of a tile is 1 if the tile is occupied, 0 otherwise) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">sparseMap</td><td>sparseMap in the current rank </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac45384427949c06440ad327a454d614c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac45384427949c06440ad327a454d614c">&#9670;&nbsp;</a></span>currentRankWorkload() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::currentRankWorkload </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the total workload on the current MPI rank </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>MPI cartesian communicator </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>total workload on current rank </dd></dl>

</div>
</div>
<a id="a0adefd6b4bbd92bc3e8f3394ed811b20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0adefd6b4bbd92bc3e8f3394ed811b20">&#9670;&nbsp;</a></span>currentRankWorkload() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<div class="memtemplate">
template&lt;typename PartitionViewHost , typename WorkloadViewHost &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::currentRankWorkload </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">PartitionViewHost &amp;&#160;</td>
          <td class="paramname"><em>rec_view</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">WorkloadViewHost &amp;&#160;</td>
          <td class="paramname"><em>prefix_sum_view</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>compute the total workload on the current MPI rank </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>MPI cartesian communicator </td></tr>
    <tr><td class="paramname">rec_view</td><td>Host mirror of _rec_partition_dev </td></tr>
    <tr><td class="paramname">prefix_sum_view</td><td>Host mirror of _workload_prefix_sum </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>total workload on current rank </dd></dl>

</div>
</div>
<a id="a88712aa69d9faaaeba720aadb3bc389d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88712aa69d9faaaeba720aadb3bc389d">&#9670;&nbsp;</a></span>initializeRecPartition()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::initializeRecPartition </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>rec_partition_i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>rec_partition_j</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>rec_partition_k</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initialize the tile partition; partition in each dimension has the form [0, p_1, ..., p_n, total_tile_num], so the partition would be [0, p_1), [p_1, p_2) ... [p_n, total_tile_num]. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rec_partition_i</td><td>partition array in dimension i </td></tr>
    <tr><td class="paramname">rec_partition_j</td><td>partition array in dimension j </td></tr>
    <tr><td class="paramname">rec_partition_k</td><td>partition array in dimension k </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af0c1e99bbd57d2964aa89fb1eef465b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0c1e99bbd57d2964aa89fb1eef465b3">&#9670;&nbsp;</a></span>optimizePartition() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::optimizePartition </td>
          <td>(</td>
          <td class="paramtype">bool &amp;&#160;</td>
          <td class="paramname"><em>is_changed</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>iter_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>optimize the partition in three dimensions seperately </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">is_changed</td><td>label if the partition is changed after the optimization </td></tr>
    <tr><td class="paramname">iter_seed</td><td>seed number to choose the starting dimension of the optimization </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1de5559f31df44046dd4fd231a9d7fd2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1de5559f31df44046dd4fd231a9d7fd2">&#9670;&nbsp;</a></span>optimizePartition() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<div class="memtemplate">
template&lt;class ParticlePosViewType , typename ArrayType , typename CellUnit &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::optimizePartition </td>
          <td>(</td>
          <td class="paramtype">const ParticlePosViewType &amp;&#160;</td>
          <td class="paramname"><em>view</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>particle_num</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ArrayType &amp;&#160;</td>
          <td class="paramname"><em>global_lower_corner</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const CellUnit&#160;</td>
          <td class="paramname"><em>dx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>iteratively optimize the partition </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">view</td><td>particle positions view </td></tr>
    <tr><td class="paramname">particle_num</td><td>total particle number </td></tr>
    <tr><td class="paramname">global_lower_corner</td><td>the coordinate of the domain global lower corner </td></tr>
    <tr><td class="paramname">dx</td><td>cell dx size </td></tr>
    <tr><td class="paramname">comm</td><td>MPI communicator used for workload reduction </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>iteration number </dd></dl>

</div>
</div>
<a id="a1db7d9a2fd6291775629256bb1fb1957"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1db7d9a2fd6291775629256bb1fb1957">&#9670;&nbsp;</a></span>optimizePartition() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<div class="memtemplate">
template&lt;class SparseMapType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::optimizePartition </td>
          <td>(</td>
          <td class="paramtype">const SparseMapType &amp;&#160;</td>
          <td class="paramname"><em>sparseMap</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>iteratively optimize the partition </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">sparseMap</td><td>sparseMap in the current rank </td></tr>
    <tr><td class="paramname">comm</td><td>MPI communicator used for workload reduction </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>iteration number </dd></dl>

</div>
</div>
<a id="a0f1ccee3a257e7c0164bd31a62391473"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f1ccee3a257e7c0164bd31a62391473">&#9670;&nbsp;</a></span>ownedCellInfo()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::ownedCellInfo </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>owned_num_cell</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>global_cell_offset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the owned number of cells and the global cell offset of the current MPI rank. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>The MPI Cartesian communicator for the partitioning. </td></tr>
    <tr><td class="paramname">owned_num_cell</td><td>(Return) The owned number of cells of the current MPI rank in each dimension. </td></tr>
    <tr><td class="paramname">global_cell_offset</td><td>(Return) The global cell offset of the current MPI rank in each dimension </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classCajita_1_1BlockPartitioner.html#a7e99a76336956b983abd2bc2a0b7e2f1">Cajita::BlockPartitioner&lt; 3 &gt;</a>.</p>

</div>
</div>
<a id="a2de4b75cfd8ae87ce76c223d0a6aa2a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2de4b75cfd8ae87ce76c223d0a6aa2a2">&#9670;&nbsp;</a></span>ownedCellsPerDimension()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::array&lt;int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a>&gt; <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::ownedCellsPerDimension </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the cell number in each dimension owned by the current MPI rank. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>MPI cartesian communicator </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a16438a4249d049575d7b2a76f1965490"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a16438a4249d049575d7b2a76f1965490">&#9670;&nbsp;</a></span>ownedTileInfo()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::ownedTileInfo </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>owned_num_tile</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>global_tile_offset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the owned number of tiles and the global tile offset of the current MPI rank. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>The MPI Cartesian communicator for the partitioning. </td></tr>
    <tr><td class="paramname">owned_num_tile</td><td>(Return) The owned number of tiles of the current MPI rank in each dimension. </td></tr>
    <tr><td class="paramname">global_tile_offset</td><td>(Return) The global tile offset of the current MPI rank in each dimension </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1e3c5f54f8fe08ec2ec88aefb8415bb7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e3c5f54f8fe08ec2ec88aefb8415bb7">&#9670;&nbsp;</a></span>ownedTilesPerDimension()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::array&lt;int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a>&gt; <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::ownedTilesPerDimension </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>cart_comm</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the tile number in each dimension owned by the current MPI rank. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cart_comm</td><td>MPI cartesian communicator </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a2a7a673396816fd06d2b026f26c036c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a7a673396816fd06d2b026f26c036c9">&#9670;&nbsp;</a></span>ranksPerDimension() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::array&lt;int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a>&gt; <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::ranksPerDimension </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Compute the number of MPI ranks in each dimension of the grid from the given MPI communicator. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">comm</td><td>The communicator to use for the partitioning </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af68f61d079af0ca032d44a1d43e2069a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af68f61d079af0ca032d44a1d43e2069a">&#9670;&nbsp;</a></span>ranksPerDimension() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::array&lt;int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a>&gt; <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::ranksPerDimension </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; int, <a class="el" href="classCajita_1_1SparseDimPartitioner.html#a652ee3297ac5b29c8b88e6042442aa6f">num_space_dim</a> &gt; &amp;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of MPI ranks in each dimension of the grid from the given MPI communicator. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">comm</td><td>The communicator to use for the partitioning </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classCajita_1_1BlockPartitioner.html#a54106083fa8a0de33f9546df38ab4c93">Cajita::BlockPartitioner&lt; 3 &gt;</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="abeffdd20e2001506d8c2b7257dc67a6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abeffdd20e2001506d8c2b7257dc67a6b">&#9670;&nbsp;</a></span>cell_bits_per_tile_dim</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr unsigned long long <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::cell_bits_per_tile_dim</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">        <a class="code" href="namespaceCajita.html#ae9bb6915655919bf33f6128dc0cf62e8">bitCount</a>( CellPerTileDim )</div>
<div class="ttc" id="anamespaceCajita_html_ae9bb6915655919bf33f6128dc0cf62e8"><div class="ttname"><a href="namespaceCajita.html#ae9bb6915655919bf33f6128dc0cf62e8">Cajita::bitCount</a></div><div class="ttdeci">constexpr KOKKOS_INLINE_FUNCTION Integer bitCount(Integer input_int) noexcept</div><div class="ttdoc">(Host/Device) Compute the lease bit number needed to index input integer</div><div class="ttdef"><b>Definition:</b> Cajita_SparseIndexSpace.hpp:73</div></div>
</div><!-- fragment -->
<p>Number of bits (per dimension) needed to index the cells inside a tile. </p>

</div>
</div>
<a id="a48f75e292caa057b5ff2bab858af6359"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48f75e292caa057b5ff2bab858af6359">&#9670;&nbsp;</a></span>cell_num_per_tile_dim</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Device , unsigned long long CellPerTileDim = 4, std::size_t NumSpaceDim = 3&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr unsigned long long <a class="el" href="classCajita_1_1SparseDimPartitioner.html">Cajita::SparseDimPartitioner</a>&lt; Device, CellPerTileDim, NumSpaceDim &gt;::cell_num_per_tile_dim</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=</div>
<div class="line">        1 &lt;&lt; <a class="code" href="classCajita_1_1SparseDimPartitioner.html#abeffdd20e2001506d8c2b7257dc67a6b">cell_bits_per_tile_dim</a></div>
<div class="ttc" id="aclassCajita_1_1SparseDimPartitioner_html_abeffdd20e2001506d8c2b7257dc67a6b"><div class="ttname"><a href="classCajita_1_1SparseDimPartitioner.html#abeffdd20e2001506d8c2b7257dc67a6b">Cajita::SparseDimPartitioner::cell_bits_per_tile_dim</a></div><div class="ttdeci">static constexpr unsigned long long cell_bits_per_tile_dim</div><div class="ttdoc">Number of bits (per dimension) needed to index the cells inside a tile.</div><div class="ttdef"><b>Definition:</b> Cajita_SparseDimPartitioner.hpp:66</div></div>
</div><!-- fragment --><p>Number of cells inside each tile (per dimension) Tile size reset to power of 2 </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>cajita/src/<a class="el" href="Cajita__SparseDimPartitioner_8hpp_source.html">Cajita_SparseDimPartitioner.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
